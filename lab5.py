# -*- coding: utf-8 -*-
"""Lab5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V8vqgEoVK3N7CcOLf8ll1Qc2nsEvrebw
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sentence_transformers import SentenceTransformer

file_path = '/content/drive/MyDrive/data_without_lemma.csv'
new_data = pd.read_csv(file_path)

new_data.head(3)

"""## Генерация эмбеддингов"""

#!pip install -U sentence-transformers

#  копирую данные без дубликатов QuestionId
unique_questions = new_data.drop_duplicates(subset=['QuestionId'], keep='first').copy()

#  Генерация эмбеддингов
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = []

for i in range(0, len(unique_questions), 100):# обработка батчами из за огромного размера
    batch = unique_questions['Body_question'].iloc[i:i+100].tolist()
    batch_embeddings = model.encode(batch,
                                  batch_size=32,
                                  convert_to_tensor=False,
                                  show_progress_bar=True)
    embeddings.extend(batch_embeddings)

#  Создам новый датафрейм для результатов
df_with_embeddings = pd.DataFrame({
    'QuestionId': unique_questions['QuestionId'].values,
    'question_text': unique_questions['Body_question'].values,  # Опционально
    'embedding': embeddings
})

# Оптимизация
df_with_embeddings['embedding'] = df_with_embeddings['embedding'].apply(
    lambda x: x.astype(np.float32) if isinstance(x, np.ndarray) else x
)

print(f"Исходный датафрейм: {len(new_data)} записей")
print(f"Результат без дублей: {len(df_with_embeddings)} записей")
print("Пример записи:")
print(df_with_embeddings.iloc[0])

df_with_embeddings.to_csv('/content/drive/MyDrive/df_with_embeddings.csv', index=False)
print("df успешно сохранен в Google Drive как df_with_embeddings.csv")
