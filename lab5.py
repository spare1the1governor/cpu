# -*- coding: utf-8 -*-
"""Lab5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V8vqgEoVK3N7CcOLf8ll1Qc2nsEvrebw
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from google.colab import drive
drive.mount('/content/drive')

"""####Произведёмзагрузку дф подходящую для данной задачи (работы с библиотекой SentenceTransformer)"""

file_path = '/content/drive/MyDrive/cleaned_answers.csv'
cl_answers_data = pd.read_csv(file_path)
file_path = '/content/drive/MyDrive/cl_questions_data.csv'
cl_questions_data = pd.read_csv(file_path)
file_path = '/content/drive/MyDrive/cl_tags_data.csv'
cl_tags_data = pd.read_csv(file_path)

"""копирую  функцию  объединения из 4 лабораторной

"""

# Для answers_data: удаляем строки, где OwnerUserId - NaN
cl_answers_data = cl_answers_data.dropna(subset=['OwnerUserId'])
# Преобразуем OwnerUserId в int
cl_answers_data['OwnerUserId'] = cl_answers_data['OwnerUserId'].astype(int)

cl_questions_data = cl_questions_data.dropna(subset=['OwnerUserId'])
cl_questions_data['OwnerUserId'] = cl_questions_data['OwnerUserId'].astype(int)
# Переименовываем Id для будущего мержа
cl_questions_data = cl_questions_data.rename(columns={'Id': 'QuestionId'})

cl_tags_data = cl_tags_data.dropna(subset=['Tag'])

# Мерджим questions_data и answers_data
# (left merge чтобы сохранить все вопросы, даже без ответов)
big_data = pd.merge(
    cl_questions_data,
    cl_answers_data,
    left_on='QuestionId',
    right_on='ParentId',
    how='left',
    suffixes=('_question', '_answer')
)

cl_tags_data = cl_tags_data.rename(columns={'Id': 'QuestionId'})
big_data_with_tags = pd.merge(
    big_data,
    cl_tags_data,
    on='QuestionId',
    how='left'
)

# 4. Удаляем дублирующиеся столбцы
columns_to_drop = ['ParentId']
for col in ['Id_x', 'Id_y']:
    if col in big_data.columns:
        columns_to_drop.append(col)
big_data = big_data.drop(columns=columns_to_drop, errors='ignore')

"""пропускаю лемматизацию, тк ОНА уменьшает количество контекста в предложении и мешает более точному составлению его векторного представления     """

big_data_with_tags = big_data_with_tags.dropna(subset=['Score_answer'])
big_data_with_tags['Score_answer'] = big_data_with_tags['Score_answer'].astype(int)
big_data_with_tags = big_data_with_tags.dropna(subset=['Id'])
big_data_with_tags['Id'] = big_data_with_tags['Id'].astype(int)
big_data_with_tags.to_csv('/content/drive/MyDrive/data_without_lemma.csv', index=False)
print("df успешно сохранен в Google Drive как data_without_lemma.csv")

file_path = '/content/drive/MyDrive/data_without_lemma.csv'
new_data = pd.read_csv(file_path)

new_data.head(3)

"""## Генерация эмбеддингов"""

!pip install -U sentence-transformers

import pandas as pd
from sentence_transformers import SentenceTransformer
import numpy as np

#  копирую данные без дубликатов QuestionId
unique_questions = new_data.drop_duplicates(subset=['QuestionId'], keep='first').copy()

#  Генерация эмбеддингов
model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = []

for i in range(0, len(unique_questions), 100):# обработка батчами из за огромного размера
    batch = unique_questions['Body_question'].iloc[i:i+100].tolist()
    batch_embeddings = model.encode(batch,
                                  batch_size=32,
                                  convert_to_tensor=False,
                                  show_progress_bar=True)
    embeddings.extend(batch_embeddings)

#  Создам новый датафрейм для результатов
df_with_embeddings = pd.DataFrame({
    'QuestionId': unique_questions['QuestionId'].values,
    'question_text': unique_questions['Body_question'].values,  # Опционально
    'embedding': embeddings
})

# Оптимизация
df_with_embeddings['embedding'] = df_with_embeddings['embedding'].apply(
    lambda x: x.astype(np.float32) if isinstance(x, np.ndarray) else x
)

print(f"Исходный датафрейм: {len(new_data)} записей")
print(f"Результат без дублей: {len(df_with_embeddings)} записей")
print("Пример записи:")
print(df_with_embeddings.iloc[0])

df_with_embeddings.to_csv('/content/drive/MyDrive/df_with_embeddings.csv', index=False)
print("df успешно сохранен в Google Drive как df_with_embeddings.csv")